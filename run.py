# 1. í•„ìš”í•œ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from flask import Flask, jsonify, request, render_template, send_from_directory, send_file # Flask ê´€ë ¨ ëª¨ë“ˆ
# OpenAI API ì‚¬ìš©
import openai
import os   # í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
import requests # HTTP ìš”ì²­ ì²˜ë¦¬
import threading
import time
import torch
import numpy as np
import scipy.io.wavfile as wav
from datetime import datetime
from transformers import AutoProcessor, MusicgenForConditionalGeneration
from flask_socketio import SocketIO, emit, join_room
from gtts import gTTS
import playsound
from CreateGoods import retrieve_goods, generate_image_prompt, generate_image  # ëª¨ë¸ ë¡œë“œ
# Llama-Index ê´€ë ¨ ëª¨ë“ˆ
from llama_index.core import Document
from llama_index.core import GPTVectorStoreIndex


# 2. Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__, template_folder="templates")  # "__main__"  # Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app.config["SECRET_KEY"] = "secret!"

# WebSocket ì„¤ì •
socketio = SocketIO(app, cors_allowed_origins="*")  # WebSocket 


# .env íŒŒì¼ì—ì„œ API í‚¤ ì§ì ‘ ì½ê¸°
with open(".env") as f:
    for line in f:
        key, value = line.strip().split("=")
        os.environ[key] = value  # í™˜ê²½ ë³€ìˆ˜ë¡œ ë“±ë¡

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY


# ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ msa-starboard ëª¨ë“ˆì—ì„œ ìƒì„±ëœ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë¡œë“œ
def collect_data():
    url = "http://52.77.19.120:8080/api/posts"  # 'msa-starboard'-'ëª¨ë“  ê²Œì‹œê¸€ ì¡°íšŒ' URL / í˜„ì¬ëŠ” ë¡œì»¬ì—ì„œ ê°€ëŠ¥(ì‹¤ì œ ì„œë¹„ìŠ¤ URLë¡œ ë³€ê²½í•´ì•¼ í•¨)
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            print('ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ')
        else:
            print(f"âŒ starboard ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {response.status_code}")
            print(response)
            return []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        return [Document(text=f"{post['title']}\n\n{post['content']}") for post in data]
    except requests.exceptions.RequestException as e:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        return []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
documents = collect_data()

# ì¸ë±ìŠ¤ ìƒì„±
index = GPTVectorStoreIndex.from_documents( documents )
# ì—”ì§„ ìƒì„±
query_engine = index.as_query_engine()



# ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# MusicGen ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆ ë‹¤ìš´ë¡œë“œí•˜ë©´ ìºì‹œë¨)
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small")


# 3. ë¼ìš°íŒ… ì²˜ë¦¬
#    í™ˆí˜ì´ì§€ êµ¬ì„±
@app.route('/') # URL, method ì§€ì •
def home():
    return render_template('home.html')

@app.route('/login')
def login():
    return render_template('login.html')
#    LMì— ì§ˆì˜í•˜ëŠ” ì¿¼ë¦¬(restful api êµ¬ì„±)
#    http://127.0.0.1:5000/query
@app.route( '/query', methods=['POST', 'GET'] )
def query():
    if request.method == 'POST':
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”„ëŸ¼í”„íŠ¸(ì§ˆë¬¸) íšë“
        question = request.json.get('question')
        print( question )

        # í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸)ì— í•œêµ­ì–´ë¡œ ìš”ì²­/ì‹¤ì œ starê°€ ë‹µë³€í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìš”ì²­ ì¶”ê°€
        korean_prompt = f"ì§ˆë¬¸: { question }\n\në‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê·¸ë¦¬ê³  ë‹µë³€ì„ ì‹¤ì œ K-pop ì—¬ìì•„ì´ëŒì´ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‘ì„±í•´ì£¼ì„¸ìš”"
        response = query_engine.query( korean_prompt )

        # ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        answer = str( response )
        return jsonify({"answer": answer})
    else:
        # html í™”ë©´ êµ¬ì„±
        return render_template( 'query.html' )


@app.route('/goods')
def goods():
    return render_template('goods.html')

@app.route('/goods_image/<string:filename>')
def serve_image(filename):
    print(f"ğŸ“‚ ìš”ì²­ëœ íŒŒì¼: {filename}")  # ìš”ì²­ëœ íŒŒì¼ëª…ì´ ì¶œë ¥ë˜ëŠ”ì§€ í™•ì¸
    return send_from_directory(os.path.join(BASE_DIR, 'goods_image'), filename)

@app.route('/api/ai/goods', methods=['POST'])
def create_goods():
    user_input = request.json.get('user_input')
    retrieved_nodes = retrieve_goods(user_input)
    optimized_prompt = generate_image_prompt(user_input, retrieved_nodes)
    print(f"ğŸ¨ ìƒì„±ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: {optimized_prompt}")
    image_url = generate_image(optimized_prompt)
    print(f"ğŸ–¼ï¸ ìƒì„±ëœ ì´ë¯¸ì§€ URL: {image_url}")

    # í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"./goods_image/{timestamp}.jpg"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    # ì´ë¯¸ì§€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„ ì €ì¥
    img_response = requests.get(image_url)
    if img_response.status_code == 200:
        with open(save_path, "wb") as file:
            file.write(img_response.content)
        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
    else:
        print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {img_response.status_code}")
        return jsonify({'error': 'ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨'}), 500

    return jsonify({'answer': 'ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!', 'image_url': save_path})


@app.route("/song")
def song_page():
    return render_template("song.html")

@app.route("/generate", methods=["POST"])
def generate_music():
    try:
        data = request.get_json()
        user_prompt = data.get("style", "default music")

        # ì‚¬ìš©ì ì…ë ¥ì„ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
        inputs = processor(
            text=[user_prompt],
            padding=True,
            return_tensors="pt",
        )

        # ëª¨ë¸ì„ ì‚¬ìš©í•´ ìŒì•… ìƒì„±
        with torch.no_grad():
            audio_values = model.generate(
                **inputs,
                do_sample=True,
                guidance_scale=3,
                max_new_tokens=512
            )

        # ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        audio_array = audio_values.cpu().detach().numpy()
        sampling_rate = model.config.audio_encoder.sampling_rate

        # WAV íŒŒì¼ë¡œ ì €ì¥
        filename = f"musicgen_{user_prompt.replace(' ', '_')}.wav"
        output_path = os.path.join("generated_music", filename)
        os.makedirs("generated_music", exist_ok=True)
        wav.write(output_path, rate=sampling_rate, data=audio_array[0, 0])

        return jsonify({"success": True, "filepath": f"/download/{filename}"})

    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route("/download/<filename>")
def download_file(filename):
    file_path = os.path.join("generated_music", filename)
    if os.path.exists(file_path):
        return send_file(file_path, as_attachment=True)
    else:
        return jsonify({"success": False, "error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."})


@app.route("/tts")
def chat_page():
    return render_template("chat.html")

# TTS ê¸°ëŠ¥
def speak(text):
    tts = gTTS(text=text, lang="ko")
    filename = "voice.mp3"
    tts.save(filename)
    playsound.playsound(filename, True)
    time.sleep(1)
    os.remove(filename)

# WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (ì±„íŒ… ê¸°ëŠ¥)
@socketio.on("join_room")
def handle_join_room(data):
    room = data["room"]
    join_room(room)
    emit("room_messages", {"messages": []}, room=room)  # ì´ˆê¸° ë©”ì‹œì§€ ì—†ìŒ

@socketio.on("send_message")
def handle_message(data):
    room = data["room"]
    message = data["message"]

    emit("receive_message", {"message": message}, room=room)

    tts_thread = threading.Thread(target=speak, args=(message,))
    tts_thread.start()



# 4. ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    socketio.run(app, host="0.0.0.0", port=5000, debug=True)
